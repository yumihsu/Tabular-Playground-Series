{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import xgboost as xgb\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from pandas.plotting import scatter_matrix\r\n",
    "\r\n",
    "from torchvision.transforms import transforms\r\n",
    "from torch import nn\r\n",
    "from torch.autograd import Variable\r\n",
    "import torch\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Load"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "origin_train = pd.read_csv(\"train.csv\")\r\n",
    "origin_test = pd.read_csv('test.csv')\r\n",
    "print(list(origin_train.columns))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['date_time', 'deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "def df_to_x_y(df):\r\n",
    "    df = df.reset_index(drop=True)\r\n",
    "    y_train = df[['target_carbon_monoxide','target_benzene','target_nitrogen_oxides']]\r\n",
    "    x_train = df.drop(columns= ['target_carbon_monoxide','target_benzene','target_nitrogen_oxides'],axis = 1)\r\n",
    "    x_train, x_valid , y_train,y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=23)\r\n",
    "    return x_train,y_train, x_valid, y_valid\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "none_train = origin_train.copy()\r\n",
    "print(len(none_train))\r\n",
    "for i in  range(1,len(none_train.columns)):\r\n",
    "    target = none_train.iloc[:,i]\r\n",
    "    scope = target.mean()+(target.std()*2)\r\n",
    "    column_name = none_train.columns[i]\r\n",
    "    none_train = none_train[none_train[column_name]<float(scope)]\r\n",
    "    print(f'{none_train.columns[i]}:{len(none_train)}')\r\n",
    "clean_df = none_train.copy()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7111\n",
      "deg_C:6873\n",
      "relative_humidity:6775\n",
      "absolute_humidity:6638\n",
      "sensor_1:6368\n",
      "sensor_2:6200\n",
      "sensor_3:5846\n",
      "sensor_4:5706\n",
      "sensor_5:5513\n",
      "target_carbon_monoxide:5276\n",
      "target_benzene:5082\n",
      "target_nitrogen_oxides:4809\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## data engine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "def feature_engine(df):\r\n",
    "    df = df.reset_index(drop = True)\r\n",
    "    # datetime_processing\r\n",
    "    datatime = df['date_time']\r\n",
    "    df['hour'] = pd.to_datetime(df['date_time']).dt.hour\r\n",
    "    df['hour'] = abs(df['hour']-12)/12\r\n",
    "\r\n",
    "    df['month'] = pd.to_datetime(df['date_time']).dt.month\r\n",
    "    df['month'] = abs(df['hour']-6)/6\r\n",
    "\r\n",
    "    df = df.drop(['date_time'],axis = 1)\r\n",
    "    # mean of senser\r\n",
    "    df['1345_mean'] = round((df['sensor_1'] + df['sensor_3']+ df['sensor_4'] + df['sensor_5'])/4,1)\r\n",
    "\r\n",
    "    # adjust mean_deg_c\r\n",
    "    gap = 1\r\n",
    "\r\n",
    "    mean_deg_c = df['deg_C'].copy()\r\n",
    "    change = 0\r\n",
    "    for i in range(1,len(mean_deg_c)-1):\r\n",
    "        #increase too much\r\n",
    "        if mean_deg_c[i-1] - mean_deg_c[i] >  gap:\r\n",
    "            mean_deg_c[i] = mean_deg_c[i-1] - gap\r\n",
    "            change +=1\r\n",
    "        #decrease too much\r\n",
    "        if mean_deg_c[i-1] - mean_deg_c[i] <  gap*-1:\r\n",
    "            mean_deg_c[i] = mean_deg_c[i-1] + gap\r\n",
    "            change +=1\r\n",
    "    df['mean_deg_c'] = mean_deg_c\r\n",
    "    df = df.drop(['deg_C'],axis = 1)\r\n",
    "    df = pd.DataFrame(df)\r\n",
    "    return df ,datatime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "source": [
    "df = clean_df.copy()\r\n",
    "df ,datatime = feature_engine(df)\r\n",
    "x_train,y_train,x_valid, y_valid = df_to_x_y(df)\r\n",
    "print(x_train.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      relative_humidity  absolute_humidity  sensor_1  sensor_2  sensor_3  \\\n",
      "1737               32.2             1.1605    1071.4    1066.8     775.7   \n",
      "2542               48.2             1.4337    1096.9     947.0     724.0   \n",
      "2937               28.6             1.2770     819.1     613.8    1108.8   \n",
      "952                41.2             1.0324    1056.6    1073.8     891.4   \n",
      "337                46.9             0.6280     898.6     547.0    1496.0   \n",
      "\n",
      "      sensor_4  sensor_5      hour     month  1345_mean  mean_deg_c  \n",
      "1737    1734.7    1160.9  0.833333  0.861111     1185.7        25.0  \n",
      "2542    1775.7    1168.0  0.416667  0.930556     1191.2        24.8  \n",
      "2937    1402.8     427.2  0.083333  0.986111      939.5        30.0  \n",
      "952     1558.7     762.3  0.500000  0.916667     1067.2        21.9  \n",
      "337     1176.1     486.9  0.666667  0.888889     1014.4        10.7  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "source": [
    "def df_to_series(df,step = 12):\r\n",
    "    for idx in range(step,len(df)):\r\n",
    "        if idx == step:\r\n",
    "            series_df = [df[idx-step:idx].values]\r\n",
    "        else :\r\n",
    "            series_df = np.concatenate([series_df,[df[idx-step:idx].values]],axis = 0)\r\n",
    "    return series_df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "source": [
    "x_train_series = torch.Tensor(df_to_series(x_train).astype('float32'))\r\n",
    "y_train_series = torch.Tensor(y_train[12:].values)\r\n",
    "x_valid_series = torch.Tensor(df_to_series(x_valid).astype('float32'))\r\n",
    "y_valid_series = torch.Tensor(y_valid[12:].values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "source": [
    "print(x_train_series.shape)\r\n",
    "print(y_train_series.shape)\r\n",
    "print(x_valid_series.shape)\r\n",
    "print(y_valid_series.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3835, 12, 11])\n",
      "torch.Size([3835, 3])\n",
      "torch.Size([950, 12, 11])\n",
      "torch.Size([950, 3])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "class RNN(nn.Module):\r\n",
    "    def __init__(self, input_size=11, hidden_layer_size=100, output_size=3):\r\n",
    "        super().__init__()\r\n",
    "        self.hidden_layer_size = hidden_layer_size\r\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\r\n",
    "        self.linear1 = nn.Linear(hidden_layer_size, hidden_layer_size)\r\n",
    "        self.linear2 = nn.Linear(hidden_layer_size, output_size)\r\n",
    "        self.bn1 = nn.BatchNorm2d(1024)\r\n",
    "        \r\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size).cuda(),\r\n",
    "                            torch.zeros(1,1,self.hidden_layer_size).cuda())\r\n",
    "\r\n",
    "    def forward(self, input_seq):\r\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1).cuda(), self.hidden_cell)\r\n",
    "        x = self.linear1(lstm_out.view(len(input_seq), -1))\r\n",
    "        predictions = self.linear2(x)\r\n",
    "        return predictions[-1]\r\n",
    "\r\n",
    "class RMSLELoss(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.mse = nn.MSELoss()\r\n",
    "\r\n",
    "    def forward(self, pred, actual):\r\n",
    "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "source": [
    "model = RNN().cuda()\r\n",
    "loss_function = RMSLELoss()\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\r\n",
    "epochs = 150\r\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RNN(\n",
      "  (lstm): LSTM(11, 100)\n",
      "  (linear1): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (linear2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "source": [
    "for i in range(epochs):\r\n",
    "    best_loss = 0.3\r\n",
    "    train_loss_sum = 0.0\r\n",
    "    valid_loss_sum = 0.0\r\n",
    "    for seq, labels in zip(x_train_series.cuda(),y_train_series.cuda()):\r\n",
    "        #train \r\n",
    "        model.train()\r\n",
    "        optimizer.zero_grad()\r\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size).cuda(),torch.zeros(1, 1, model.hidden_layer_size).cuda())\r\n",
    "        y_pred = model(seq.cuda())\r\n",
    "\r\n",
    "        train_loss = loss_function(y_pred.cuda(), labels.cuda())\r\n",
    "        train_loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        #valid \r\n",
    "    for seq, labels in zip(x_valid_series,y_valid_series):\r\n",
    "        model.eval()\r\n",
    "        y_pred = model(seq.cuda())\r\n",
    "        valid_loss = loss_function(y_pred.cuda(), labels.cuda())\r\n",
    "\r\n",
    "    if i%5 == 1:\r\n",
    "        print(f'epoch: {i:3} train_loss: {train_loss.item():10.8f}:valid_loss: {valid_loss.item():10.8f}')\r\n",
    "\r\n",
    "    if valid_loss < best_loss:\r\n",
    "        best_loss = valid_loss\r\n",
    "        torch.save(model,'/0816_01_model.pt')\r\n",
    "        torch.save(model.state_dict(),'/0816_01_dict.pt')\r\n",
    "        print(f'Current best is {best_loss:10.8f}')\r\n",
    "print(f'epoch: {i:3} train_loss: {train_loss.item():10.8f}:valid_loss: {valid_loss.item():10.8f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch:   1 train_loss: 0.33404896:valid_loss: 0.31100070\n",
      "Current best is 0.20284870\n",
      "Current best is 0.15981987\n",
      "Current best is 0.15374243\n",
      "Current best is 0.16280587\n",
      "epoch:   6 train_loss: 0.48448703:valid_loss: 0.17505269\n",
      "Current best is 0.17505269\n",
      "Current best is 0.18572873\n",
      "Current best is 0.19414829\n",
      "Current best is 0.20051369\n",
      "Current best is 0.20525654\n",
      "epoch:  11 train_loss: 0.52740455:valid_loss: 0.20876364\n",
      "Current best is 0.20876364\n",
      "Current best is 0.21133794\n",
      "Current best is 0.21322104\n",
      "Current best is 0.21460883\n",
      "Current best is 0.21561192\n",
      "epoch:  16 train_loss: 0.53658223:valid_loss: 0.21632990\n",
      "Current best is 0.21632990\n",
      "Current best is 0.21684374\n",
      "Current best is 0.21720785\n",
      "Current best is 0.21747276\n",
      "Current best is 0.21764776\n",
      "epoch:  21 train_loss: 0.53888059:valid_loss: 0.21775483\n",
      "Current best is 0.21775483\n",
      "Current best is 0.21781777\n",
      "Current best is 0.21794477\n",
      "Current best is 0.21802364\n",
      "Current best is 0.21803035\n",
      "epoch:  26 train_loss: 0.53986382:valid_loss: 0.21801166\n",
      "Current best is 0.21801166\n",
      "Current best is 0.21797705\n",
      "Current best is 0.21793602\n",
      "Current best is 0.21789408\n",
      "Current best is 0.21785180\n",
      "epoch:  31 train_loss: 0.54034442:valid_loss: 0.21782629\n",
      "Current best is 0.21782629\n",
      "Current best is 0.21781413\n",
      "Current best is 0.21777278\n",
      "Current best is 0.21771775\n",
      "Current best is 0.21765482\n",
      "epoch:  36 train_loss: 0.54075068:valid_loss: 0.21758673\n",
      "Current best is 0.21758673\n",
      "Current best is 0.21751480\n",
      "Current best is 0.21744084\n",
      "Current best is 0.21736558\n",
      "Current best is 0.21729060\n",
      "epoch:  41 train_loss: 0.54100758:valid_loss: 0.21721488\n",
      "Current best is 0.21721488\n",
      "Current best is 0.21713910\n",
      "Current best is 0.21706356\n",
      "Current best is 0.21698900\n",
      "Current best is 0.21691480\n",
      "epoch:  46 train_loss: 0.54124135:valid_loss: 0.21684027\n",
      "Current best is 0.21684027\n",
      "Current best is 0.21676479\n",
      "Current best is 0.21668816\n",
      "Current best is 0.21661085\n",
      "Current best is 0.21653371\n",
      "epoch:  51 train_loss: 0.54145247:valid_loss: 0.21645807\n",
      "Current best is 0.21645807\n",
      "Current best is 0.21638563\n",
      "Current best is 0.21631357\n",
      "Current best is 0.21626595\n",
      "Current best is 0.21617670\n",
      "epoch:  56 train_loss: 0.54170901:valid_loss: 0.21610790\n",
      "Current best is 0.21610790\n",
      "Current best is 0.21612319\n",
      "Current best is 0.21614790\n",
      "Current best is 0.21610929\n",
      "Current best is 0.21606569\n",
      "epoch:  61 train_loss: 0.54222989:valid_loss: 0.21600015\n",
      "Current best is 0.21600015\n",
      "Current best is 0.21595672\n",
      "Current best is 0.21588495\n",
      "Current best is 0.21583118\n",
      "Current best is 0.21576376\n",
      "epoch:  66 train_loss: 0.54256219:valid_loss: 0.21568584\n",
      "Current best is 0.21568584\n",
      "Current best is 0.21561199\n",
      "Current best is 0.21555069\n",
      "Current best is 0.21547672\n",
      "Current best is 0.21541800\n",
      "epoch:  71 train_loss: 0.54280514:valid_loss: 0.21534303\n",
      "Current best is 0.21534303\n",
      "Current best is 0.21528177\n",
      "Current best is 0.21520956\n",
      "Current best is 0.21516533\n",
      "Current best is 0.21509185\n",
      "epoch:  76 train_loss: 0.54304421:valid_loss: 0.21501774\n",
      "Current best is 0.21501774\n",
      "Current best is 0.21496049\n",
      "Current best is 0.21488969\n",
      "Current best is 0.21484467\n",
      "Current best is 0.21477129\n",
      "epoch:  81 train_loss: 0.54329628:valid_loss: 0.21472560\n",
      "Current best is 0.21472560\n",
      "Current best is 0.21466790\n",
      "Current best is 0.21460979\n",
      "Current best is 0.21454935\n",
      "Current best is 0.21446620\n",
      "epoch:  86 train_loss: 0.54355019:valid_loss: 0.21445563\n",
      "Current best is 0.21445563\n",
      "Current best is 0.21437064\n",
      "Current best is 0.21431720\n",
      "Current best is 0.21425991\n",
      "Current best is 0.21420574\n",
      "epoch:  91 train_loss: 0.54374111:valid_loss: 0.21414934\n",
      "Current best is 0.21414934\n",
      "Current best is 0.21409538\n",
      "Current best is 0.21404040\n",
      "Current best is 0.21398664\n",
      "Current best is 0.21393223\n",
      "epoch:  96 train_loss: 0.54395264:valid_loss: 0.21387854\n",
      "Current best is 0.21387854\n",
      "Current best is 0.21382548\n",
      "Current best is 0.21377204\n",
      "Current best is 0.21371940\n",
      "Current best is 0.21366642\n",
      "epoch: 101 train_loss: 0.54415375:valid_loss: 0.21361436\n",
      "Current best is 0.21361436\n",
      "Current best is 0.21356179\n",
      "Current best is 0.21351032\n",
      "Current best is 0.21345843\n",
      "Current best is 0.21340738\n",
      "epoch: 106 train_loss: 0.54434514:valid_loss: 0.21335647\n",
      "Current best is 0.21335647\n",
      "Current best is 0.21330531\n",
      "Current best is 0.21325798\n",
      "Current best is 0.21317600\n",
      "Current best is 0.21313737\n",
      "epoch: 111 train_loss: 0.54456186:valid_loss: 0.21313514\n",
      "Current best is 0.21313514\n",
      "Current best is 0.21339390\n",
      "Current best is 0.21386649\n",
      "Current best is 0.21399103\n",
      "Current best is 0.21409871\n",
      "epoch: 116 train_loss: 0.54617327:valid_loss: 0.21422598\n",
      "Current best is 0.21422598\n",
      "Current best is 0.21440302\n",
      "Current best is 0.21455540\n",
      "Current best is 0.21468049\n",
      "Current best is 0.21475872\n",
      "epoch: 121 train_loss: 0.54717213:valid_loss: 0.21479286\n",
      "Current best is 0.21479286\n",
      "Current best is 0.21480796\n",
      "Current best is 0.21480505\n",
      "Current best is 0.21479538\n",
      "Current best is 0.21477728\n",
      "epoch: 126 train_loss: 0.54754776:valid_loss: 0.21475475\n",
      "Current best is 0.21475475\n",
      "Current best is 0.21472655\n",
      "Current best is 0.21469763\n",
      "Current best is 0.21466531\n",
      "Current best is 0.21463300\n",
      "epoch: 131 train_loss: 0.54778713:valid_loss: 0.21459907\n",
      "Current best is 0.21459907\n",
      "Current best is 0.21456586\n",
      "Current best is 0.21453238\n",
      "Current best is 0.21450017\n",
      "Current best is 0.21446797\n",
      "epoch: 136 train_loss: 0.54799843:valid_loss: 0.21443081\n",
      "Current best is 0.21443081\n",
      "Current best is 0.21439812\n",
      "Current best is 0.21437596\n",
      "Current best is 0.21433072\n",
      "Current best is 0.21428978\n",
      "epoch: 141 train_loss: 0.54819167:valid_loss: 0.21426141\n",
      "Current best is 0.21426141\n",
      "Current best is 0.21422759\n",
      "Current best is 0.21419135\n",
      "Current best is 0.21415856\n",
      "Current best is 0.21412325\n",
      "epoch: 146 train_loss: 0.54837352:valid_loss: 0.21409266\n",
      "Current best is 0.21409266\n",
      "Current best is 0.21405546\n",
      "Current best is 0.21402274\n",
      "Current best is 0.21398635\n",
      "epoch: 149 train_loss: 0.54847038:valid_loss: 0.21398635\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "source": [
    "before_x_test = clean_df.copy().tail(12).reset_index(drop = True)\r\n",
    "before_x_test = before_x_test.drop(['target_carbon_monoxide','target_benzene','target_nitrogen_oxides'],axis = 1)\r\n",
    "test_df = pd.concat([before_x_test,origin_test],axis = 0)\r\n",
    "test_df = test_df.reset_index(drop=True)\r\n",
    "x_test , datatime = feature_engine(test_df)\r\n",
    "x_test_series = torch.Tensor(df_to_series(x_test.astype('float32')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "source": [
    "model.eval()\r\n",
    "result = []\r\n",
    "for sqe in x_test_series:\r\n",
    "    pred = model(sqe.cuda())\r\n",
    "\r\n",
    "    break\r\n",
    "pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 382
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# export result"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = pd.DataFrame([datatime,xgb_reg0_pred_test,xgb_reg1_pred_test,xgb_reg2_pred_test]).T\r\n",
    "result.columns=['date_time','target_carbon_monoxide','target_benzene','target_nitrogen_oxides']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result.to_csv('sub_0809_04.csv',index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0ce7a1c0a7576f4f79bb5f1e164786d063e209fd2474cc37bbb3f2c287198af"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}